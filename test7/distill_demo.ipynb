{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97de17a1",
   "metadata": {},
   "source": [
    "# Qwen Distillation Demo\n",
    "\n",
    "This notebook consolidates the core code from `test7` and walks through:\n",
    "1. Fetching K-line data from EastMoney.\n",
    "2. Building a simple prompt dataset.\n",
    "3. Generating teacher responses.\n",
    "4. Distilling a smaller student model.\n",
    "\n",
    "All steps run on small models so the demo fits in limited memory.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2392949b",
   "metadata": {},
   "source": [
    "## 1. Install dependencies\n",
    "\n",
    "The demo relies on common libraries from the `test7` project. The cell below installs the minimal set required for a CPU run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ee35a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip -q install torch transformers datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27424870",
   "metadata": {},
   "source": [
    "## 2. Imports and utility setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d5d9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, math, requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "982ceb91",
   "metadata": {},
   "source": [
    "## 3. Fetch recent K-line data\n",
    "\n",
    "The code below is adapted from `src/data/eastmoney_client.py` and `scripts/fetch_eastmoney.py` to retrieve recent daily K-line data for a given stock code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d96db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_secid(symbol: str) -> str:\n",
    "    symbol = symbol.upper()\n",
    "    if symbol.startswith(('SH', 'SZ')):\n",
    "        code = symbol[-6:]\n",
    "        prefix = symbol[:2]\n",
    "    else:\n",
    "        code = symbol[-6:]\n",
    "        prefix = 'SH' if code[0] in {'5','6','9'} else 'SZ'\n",
    "    exch = '1' if prefix == 'SH' else '0'\n",
    "    return f\"{exch}.{code}\"\n",
    "\n",
    "def fetch_kline(secid: str, beg: str, end: str,\n",
    "                fields1: str=\"f1,f2,f3,f4,f5,f6\",\n",
    "                fields2: str=\"f51,f52,f53,f54,f55,f56,f57,f58,f59,f60,f61,f116\"):\n",
    "    url = \"https://push2his.eastmoney.com/api/qt/stock/kline/get\"\n",
    "    params = {\n",
    "        'secid': secid,\n",
    "        'beg': beg,\n",
    "        'end': end,\n",
    "        'klt': 101,\n",
    "        'fqt': 1,\n",
    "        'fields1': fields1,\n",
    "        'fields2': fields2,\n",
    "    }\n",
    "    resp = requests.get(url, params=params, timeout=10)\n",
    "    resp.raise_for_status()\n",
    "    return resp.json()\n",
    "\n",
    "def parse_kline_json(raw):\n",
    "    klines = raw.get('data', {}).get('klines', [])\n",
    "    rows = []\n",
    "    for item in klines:\n",
    "        parts = item.split(',')\n",
    "        rows.append({\n",
    "            'date': parts[0],\n",
    "            'open': float(parts[1]),\n",
    "            'close': float(parts[2]),\n",
    "            'high': float(parts[3]),\n",
    "            'low': float(parts[4]),\n",
    "            'volume': float(parts[5]),\n",
    "            'turnover': float(parts[6])\n",
    "        })\n",
    "    return rows\n",
    "\n",
    "def get_recent_kline(symbol: str, days: int = 30):\n",
    "    secid = to_secid(symbol)\n",
    "    end = pd.Timestamp.today().strftime('%Y%m%d')\n",
    "    beg = (pd.Timestamp.today() - pd.Timedelta(days=days*2)).strftime('%Y%m%d')\n",
    "    raw = fetch_kline(secid, beg, end)\n",
    "    rows = parse_kline_json(raw)\n",
    "    df = pd.DataFrame(rows)\n",
    "    if not df.empty:\n",
    "        df['date'] = pd.to_datetime(df['date'])\n",
    "        df.sort_values('date', inplace=True)\n",
    "        df = df.tail(days)\n",
    "    return df\n",
    "\n",
    "symbol = '600519'\n",
    "kline_df = get_recent_kline(symbol, days=30)\n",
    "print(kline_df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0411bdc0",
   "metadata": {},
   "source": [
    "## 4. Build prompt sample\n",
    "\n",
    "We convert the K-line table into a text prompt that asks the model to provide a prediction, analysis and advice. The utility mirrors `build_prompts_from_kline` from the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "976647aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEMPLATE = (\n",
    "    \"股票 {stock_code} 近30日K线数据: {kline_json}\n",
    "\"\n",
    "    \"涨跌幅: {change}%。请预测后市走势，给出简短分析和操作建议，\"\n",
    "    \"并以 JSON 格式回复，包括 'prediction', 'analysis', 'advice' 三个字段。\"\n",
    ")\n",
    "\n",
    "def build_prompt_from_df(df: pd.DataFrame, stock_code: str) -> str:\n",
    "    df = df.copy()\n",
    "    change = ((df['close'].iloc[-1] / df['close'].iloc[0]) - 1) * 100\n",
    "    records = df[['date','open','close','high','low','volume']]\n",
    "    records['date'] = records['date'].dt.strftime('%Y-%m-%d')\n",
    "    kline_json = records.to_dict(orient='records')\n",
    "    return TEMPLATE.format(stock_code=stock_code, kline_json=json.dumps(kline_json, ensure_ascii=False), change=round(change,2))\n",
    "\n",
    "prompt = build_prompt_from_df(kline_df, symbol)\n",
    "print(prompt[:200] + '...')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a174dd2d",
   "metadata": {},
   "source": [
    "## 5. Teacher model generation\n",
    "\n",
    "For demonstration we use the lightweight `distilgpt2` model as the teacher. It produces a JSON-like answer for the prompt above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe54d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_model = AutoModelForCausalLM.from_pretrained('distilgpt2')\n",
    "teacher_tokenizer = AutoTokenizer.from_pretrained('distilgpt2')\n",
    "\n",
    "inputs = teacher_tokenizer(prompt, return_tensors='pt')\n",
    "with torch.no_grad():\n",
    "    teacher_output = teacher_model.generate(**inputs, max_new_tokens=64)\n",
    "\n",
    "teacher_text = teacher_tokenizer.decode(teacher_output[0], skip_special_tokens=True)\n",
    "print(teacher_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b18b481",
   "metadata": {},
   "source": [
    "## 6. Distill to a tiny student\n",
    "\n",
    "We fine-tune a much smaller `sshleifer/tiny-gpt2` model so that its logits match the teacher's on the same prompt. This captures the essence of logits-based knowledge distillation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b58762df",
   "metadata": {},
   "outputs": [],
   "source": [
    "student_model = AutoModelForCausalLM.from_pretrained('sshleifer/tiny-gpt2')\n",
    "student_tokenizer = AutoTokenizer.from_pretrained('sshleifer/tiny-gpt2')\n",
    "\n",
    "# Use teacher tokenizer to align vocab\n",
    "inputs = teacher_tokenizer(prompt, return_tensors='pt')\n",
    "with torch.no_grad():\n",
    "    teacher_logits = teacher_model(**inputs).logits\n",
    "\n",
    "optimizer = torch.optim.AdamW(student_model.parameters(), lr=1e-3)\n",
    "T = 2.0  # temperature\n",
    "for step in range(100):\n",
    "    student_logits = student_model(**inputs).logits\n",
    "    loss = F.kl_div(\n",
    "        F.log_softmax(student_logits / T, dim=-1),\n",
    "        F.softmax(teacher_logits / T, dim=-1),\n",
    "        reduction='batchmean'\n",
    "    ) * (T**2)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    if step % 20 == 0:\n",
    "        print(f\"step {step}: loss={loss.item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "965dd128",
   "metadata": {},
   "source": [
    "## 7. Student model output\n",
    "\n",
    "After distillation, the student generates its own response to the same prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb77c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "student_output = student_model.generate(**inputs, max_new_tokens=64)\n",
    "student_text = teacher_tokenizer.decode(student_output[0], skip_special_tokens=True)\n",
    "print(student_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "104302a3",
   "metadata": {},
   "source": [
    "The notebook demonstrated how raw market data can be turned into prompts and how a smaller model can be distilled from a larger one using logits matching—all within a single, self-contained workflow."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
